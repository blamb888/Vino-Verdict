{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers\n",
    "pip install gcsfs\n",
    "!nvidia-smi\n",
    "from transformers import get_linear_schedule_with_warmup, BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim import AdamW\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the CSV file in GCS\n",
    "csv_path = \"gs://vino-verdict/data/cleaned_wine_df.csv\"\n",
    "\n",
    "# Read the CSV using pandas\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "df.head(3)\n",
    "\n",
    "# 1. Preprocess the `description` column\n",
    "\n",
    "# Check for missing values in the description and points columns\n",
    "missing_values = df[['description', 'points']].isnull().sum()\n",
    "\n",
    "# Drop rows with missing descriptions (if any)\n",
    "df = df.dropna(subset=['description'])\n",
    "\n",
    "# 2. Transform the `points` column into categorical labels\n",
    "\n",
    "# Define bins for the wine ratings and labels for each bin\n",
    "bins = [80, 89, 100]  # Note: We start at 79 to ensure 80 is included in the 'bad' category due to the nature of how bins are defined\n",
    "labels = ['bad', 'good']\n",
    "\n",
    "# Create a new column 'rating_category' with the binned labels\n",
    "df['rating_category'] = pd.cut(df['points'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "missing_values, df[['description', 'rating_category']].head()\n",
    "\n",
    "df['rating_category'].value_counts()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['rating_category'], random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['rating_category'], random_state=42)\n",
    "\n",
    "# Apply lambda function to create 'binary_label' column\n",
    "train_df['binary_label'] = train_df['sentiment_score'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "valid_df['binary_label'] = valid_df['sentiment_score'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "test_df['binary_label'] = test_df['sentiment_score'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "\n",
    "train_df.shape, valid_df.shape, test_df.shape\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# Tokenize the descriptions\n",
    "train_encodings = tokenizer.batch_encode_plus(\n",
    "    list(train_df['description'].values),  # Convert to a list\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=150,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "valid_encodings = tokenizer.batch_encode_plus(\n",
    "    list(valid_df['description'].values),  # Convert to a list\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=150,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer.batch_encode_plus(\n",
    "    list(test_df['description'].values),  # Convert to a list\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=150,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Extract the input IDs, attention masks, and labels\n",
    "train_labels = train_df['rating_category'].astype('category').cat.codes.values\n",
    "valid_labels = valid_df['rating_category'].astype('category').cat.codes.values\n",
    "test_labels = test_df['rating_category'].astype('category').cat.codes.values\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Convert data into torch tensors for training set\n",
    "train_input_ids = train_encodings['input_ids'].clone().detach()\n",
    "train_attention_masks = train_encodings['attention_mask'].clone().detach()\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "# Convert data into torch tensors for validation set\n",
    "valid_input_ids = valid_encodings['input_ids'].clone().detach()\n",
    "valid_attention_masks = valid_encodings['attention_mask'].clone().detach()\n",
    "valid_labels = torch.tensor(valid_labels, dtype=torch.long)\n",
    "\n",
    "# Convert data into torch tensors for test set\n",
    "test_input_ids = test_encodings['input_ids'].clone().detach()\n",
    "test_attention_masks = test_encodings['attention_mask'].clone().detach()\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Create tensor datasets\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "valid_dataset = TensorDataset(valid_input_ids, valid_attention_masks, valid_labels)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create dataloaders\n",
    "\n",
    "# Training dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Validation dataloader\n",
    "validation_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    sampler=SequentialSampler(valid_dataset),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Test dataloader\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=SequentialSampler(test_dataset),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training hyperparameters and initialization\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "gradient_accumulation_steps = 1\n",
    "max_grad_norm = 1.0\n",
    "patience = 2\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_f1_scores = []\n",
    "best_val_loss = float('inf')\n",
    "no_improve_epochs = 0\n",
    "best_val_f1 = 0\n",
    "path_to_save = \"gs://vino-verdict/models/multilingual-uncased-sentiment.bin\"\n",
    "\n",
    "# Compute class weights and convert to torch tensor\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(df['rating_category']), y=df['rating_category'])\n",
    "class_weights = torch.tensor(class_weights).float().to(device)\n",
    "# Consider using SMOTE during preprocessing instead of the prebuilt class weights\n",
    "\n",
    "# Set up the data loaders using the previously defined datasets\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(valid_dataset, sampler=SequentialSampler(valid_dataset), batch_size=batch_size)\n",
    "\n",
    "# Load model directly\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# Loss function for binary cross entropy\n",
    "loss_function = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.005)\n",
    "# Look into perhaps using a Learning Rate Decay\n",
    "# This starts with a higher learning rate and slowly reduces it\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    val_losses_epoch = []  # List to store validation losses for this epoch\n",
    "    start_time = time.time()  # Start time for the epoch\n",
    "\n",
    "    print(f\"Training Epoch {epoch + 1}/{epochs}\")\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits  # Get the logits from the model\n",
    "        # Apply sigmoid activation to convert logits into probabilities\n",
    "        probs = torch.sigmoid(logits)\n",
    "    \n",
    "        loss = loss_function(probs, inputs['labels'].float())  # BCE loss expects float labels\n",
    "        loss = loss / gradient_accumulation_steps  # Adjust the loss for gradient accumulation\n",
    "        loss.backward()\n",
    "\n",
    "        if (step + 1) % 50 == 0:\n",
    "            print(f\"Batch {step + 1} of {len(train_dataloader)}. Loss: {loss.item():.4f}.\")\n",
    "\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            # Clip gradients to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update the learning rate\n",
    "            model.zero_grad()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # Log learning rate every 200 batches\n",
    "        if (step + 1) % 200 == 0:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    # Calculate average training loss\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    end_time = time.time()  # End time for the epoch\n",
    "    epoch_duration = end_time - start_time\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print current learning rate for monitoring\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    for step, batch in enumerate(validation_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=batch[0], attention_mask=batch[1])\n",
    "            logits = outputs.logits\n",
    "            probs = torch.sigmoid(logits)\n",
    "    \n",
    "        predicted_labels = (probs >= 0.5).int()  # Applying threshold\n",
    "        \n",
    "        # Calculate validation loss for early stopping\n",
    "        val_loss = loss_function(logits, batch[2])\n",
    "        val_losses_epoch.append(val_loss.item())\n",
    "\n",
    "    \n",
    "        # Print validation progress every 50 batches\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Validation Batch {step} of {len(validation_dataloader)}\")\n",
    "\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_accuracy = accuracy_score(true_vals, predictions)\n",
    "    val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f} - F1 Score: {val_f1:.4f}\")\n",
    "    \n",
    "    # Append metrics to their respective lists\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "\n",
    "    val_losses.append(np.mean(val_losses_epoch))\n",
    "    avg_val_loss = np.mean(val_losses_epoch)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Early stopping check\n",
    "    if np.mean(val_losses_epoch) < best_val_loss:\n",
    "        best_val_loss = np.mean(val_losses_epoch)\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs == patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
    "            break\n",
    "\n",
    "    # Save the model if it's the best one seen so far\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        print(\"Saving the best model...\")\n",
    "\n",
    "        # Save model weights\n",
    "        torch.save(model.state_dict(), \"./multilingual-uncased-sentiment.bin\")\n",
    "        os.system(f\"gsutil cp ./multilingual-uncased-sentiment.bin {path_to_save}\")\n",
    "\n",
    "        # Save the model's configuration\n",
    "        config_path = \"./multilingual-uncased-sentiment_config.json\"\n",
    "        model.config.to_json_file(config_path)\n",
    "        os.system(f\"gsutil cp {config_path} gs://vino-verdict/models/\")\n",
    "\n",
    "# After training is done, evaluate the model on the test dataset\n",
    "model.eval()\n",
    "predictions, true_vals = [], []\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=batch[0], attention_mask=batch[1])\n",
    "\n",
    "    logits = outputs[0]  # Keep logits as tensors on the GPU\n",
    "    probabilities = torch.sigmoid(logits)  # Apply sigmoid to convert logits to probabilities\n",
    "    predicted_labels = (probabilities >= 0.5).cpu().numpy()  # Convert probabilities to binary labels\n",
    "    predictions.extend(predicted_labels)  # Extend the list with predicted binary labels\n",
    "    true_vals.extend(batch[2].cpu().numpy())\n",
    "\n",
    "# Flatten the true_vals and predictions lists\n",
    "true_vals = [label for sublist in true_vals for label in sublist]\n",
    "predictions = [label for sublist in predictions for label in sublist]\n",
    "\n",
    "# Calculate test metrics\n",
    "test_accuracy = accuracy_score(true_vals, predictions)\n",
    "test_f1 = f1_score(true_vals, predictions, average='binary')  # Use 'binary' average for binary classification\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} - F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "print(5)\n",
    "print(len(val_accuracies))\n",
    "print(len(val_f1_scores))\n",
    "print(len(val_losses))\n",
    "print(len(train_losses))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# Assuming predictions and true_vals are already computed\n",
    "predictions = predictions\n",
    "true_vals = true_vals\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_vals, predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Compute F1 score\n",
    "f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_vals, predictions)\n",
    "\n",
    "# Convert the numpy array to a list of lists for easy printing\n",
    "cm_list = cm.tolist()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm_list)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your data\n",
    "epochs_range = list(range(1, len(train_losses) + 1))\n",
    "training_losses = train_losses\n",
    "validation_accuracies = val_accuracies\n",
    "validation_f1_scores = val_f1_scores\n",
    "validation_losses = val_losses\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Overlay Training and Validation Loss\n",
    "plt.plot(epochs_range, train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(epochs_range, val_losses, label='Validation Loss', color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
