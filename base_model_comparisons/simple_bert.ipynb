{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file in GCS\n",
    "csv_path = \"gs://vino-verdict/data/cleaned_wine_df.csv\"\n",
    "\n",
    "# Read the CSV using pandas\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the `description` column\n",
    "missing_values = df[['description', 'points']].isnull().sum()\n",
    "df = df.dropna(subset=['description'])\n",
    "\n",
    "# Transform the `points` column into categorical labels\n",
    "bins = [0, 85, 90, 100]\n",
    "labels = ['low', 'medium', 'high']\n",
    "df['rating_category'] = pd.cut(df['points'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "missing_values, df[['description', 'rating_category']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize descriptions\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for desc in df['description']:\n",
    "    encoded_dict = tokenizer.encode_plus(desc, add_special_tokens=True, max_length=64, truncation=True, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# Convert rating categories to integers (0: low, 1: medium, 2: high)\n",
    "labels = df['rating_category'].map({'low': 0, 'medium': 1, 'high': 2}).values\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"Train size: {train_size}, Validation size: {val_size}, Test size: {test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(train_dataset, sampler=torch.utils.data.RandomSampler(train_dataset), batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(val_dataset, sampler=torch.utils.data.SequentialSampler(val_dataset), batch_size=BATCH_SIZE)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3)  # 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(3):\n",
    "    total_train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_val_accuracy = 0\n",
    "for batch in val_dataloader:\n",
    "    b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    total_val_accuracy += (logits.argmax(axis=1) == label_ids).mean()\n",
    "print(f\"Validation Accuracy: {total_val_accuracy / len(val_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_test_accuracy = 0\n",
    "for batch in DataLoader(test_dataset, sampler=torch.utils.data.SequentialSampler(test_dataset), batch_size=BATCH_SIZE):\n",
    "    b_input_ids, b_input_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    total_test_accuracy += (logits.argmax(axis=1) == label_ids).mean()\n",
    "print(f\"Test Accuracy: {total_test_accuracy / len(DataLoader(test_dataset, sampler=torch.utils.data.SequentialSampler(test_dataset), batch_size=BATCH_SIZE))}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
